#combining two graph p1 and p2
library(gridExtra)
grid.arrange(p1,p2,ncol=2)
# Summary of the simple regression and polynomial regression
print(summary(simp_regressor))
print(summary(poly_regressor))
source('~/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 6 - Polynomial Regression/Polynomial_Regression/polinomial_egression_udhayan.R', echo=TRUE)
x_grid_val = seq(min(training_set$Level), max(training_set$Level), 0.1)
x_grid_val
geom_line(aes( x = x_grid_val, y = predict(poly_regressor, newdata = data.frame(Level = x_grid_val))),
colour = 'blue')+
p_dataset = read.csv("Position_Salaries.csv")
# spliting the data_set
library(caTools)
set.seed(123)
to_split = sample.split(p_dataset$Salary,SplitRatio = 0.9)
training_set = subset(p_dataset,to_split == TRUE)
test_set = subset(p_dataset,to_split == FALSE)
# training(fitting) the data_set simple linear
simp_regressor = lm(formula ='Salary ~ Level' ,
data = training_set)
# adding new coloum to dataset for polynomial
p_dataset$Level2 = p_dataset$Level^2 # take care of the input and output of dataset
training_set$Level2 = training_set$Level^2
training_set$Level3 = training_set$Level^3
training_set$Level4 = training_set$Level^4
training_set$Level5 = training_set$Level^5
# training(fitting) the data_set poly linear
poly_regressor = lm(formula ='Salary ~ Level + Level2 + Level3 + Level4 ' ,
data = training_set)
# visualizing simple linear
# Training set with test set
library(ggplot2)
p1 <- ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(simp_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = training_set$Level, y = predict(simp_regressor, newdata = training_set)),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
# adding new coloum to dataset (test set) to plot for polynomial
test_set$Level2 = test_set$Level^2
test_set$Level3 = test_set$Level^3
test_set$Level4 = test_set$Level^4
test_set$Level5 = test_set$Level^5
#install.packages("gridExtra") for displaying two plot
# visualizing poly linear
# Training set with test set
library(ggplot2)
x_grid_val = seq(min(training_set$Level), max(training_set$Level), 0.1)
p2 <- ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(poly_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = x_grid_val, y = predict(poly_regressor, newdata = data.frame(Level = x_grid_val))),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
#combining two graph p1 and p2
library(gridExtra)
grid.arrange(p1,p2,ncol=2)
# Summary of the simple regression and polynomial regression
print(summary(simp_regressor))
print(summary(poly_regressor))
p_dataset = read.csv("Position_Salaries.csv")
# spliting the data_set
library(caTools)
set.seed(123)
to_split = sample.split(p_dataset$Salary,SplitRatio = 0.9)
training_set = subset(p_dataset,to_split == TRUE)
test_set = subset(p_dataset,to_split == FALSE)
# training(fitting) the data_set simple linear
simp_regressor = lm(formula ='Salary ~ Level' ,
data = training_set)
# adding new coloum to dataset for polynomial
p_dataset$Level2 = p_dataset$Level^2 # take care of the input and output of dataset
training_set$Level2 = training_set$Level^2
training_set$Level3 = training_set$Level^3
training_set$Level4 = training_set$Level^4
training_set$Level5 = training_set$Level^5
# training(fitting) the data_set poly linear
poly_regressor = lm(formula ='Salary ~ Level + Level2 + Level3 + Level4 ' ,
data = training_set)
# visualizing simple linear
# Training set with test set
library(ggplot2)
p1 <- ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(simp_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = training_set$Level, y = predict(simp_regressor, newdata = training_set)),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
# adding new coloum to dataset (test set) to plot for polynomial
test_set$Level2 = test_set$Level^2
test_set$Level3 = test_set$Level^3
test_set$Level4 = test_set$Level^4
test_set$Level5 = test_set$Level^5
#install.packages("gridExtra") for displaying two plot
# visualizing poly linear
# Training set with test set
library(ggplot2)
x_grid_val = seq(min(training_set$Level), max(training_set$Level), 0.1)
ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(poly_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = x_grid_val, y = predict(poly_regressor, newdata = data.frame(Level = x_grid_val))),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
#combining two graph p1 and p2
library(gridExtra)
#grid.arrange(p1,p2,ncol=2)
# Summary of the simple regression and polynomial regression
print(summary(simp_regressor))
print(summary(poly_regressor))
# Training set with test set
library(ggplot2)
x_grid_val = seq(min(training_set$Level), max(training_set$Level), 0.1)
ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(poly_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = x_grid_val, y = predict(poly_regressor, newdata = data.frame(Level = x_grid_val))),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
library(ggplot2)
x_grid_val = seq(min(training_set$Level), max(training_set$Level), 0.1)
ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(poly_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = x_grid_val, y = predict(poly_regressor, newdata = data.frame(Level = x_grid_val))),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
predict(poly_regressor, newdata = data.frame(Level = x_grid_val))
y_pred_t = predict(poly_regressor, newdata = training_set)
y_pred_t
y_grid_val = seq(min(y_pred_t), max(y_pred_t), 0.1)
y_grid_val
library(ggplot2)
y_pred_t = predict(poly_regressor, newdata = training_set)
x_grid_val = seq(min(training_set$Level), max(training_set$Level), 0.1)
y_grid_val = seq(min(y_pred_t), max(y_pred_t), 0.1)
p2 <-ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(poly_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = training_set$Level, y = data.frame(Level = y_grid_val)),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
p_dataset = read.csv("Position_Salaries.csv")
# spliting the data_set
library(caTools)
set.seed(123)
to_split = sample.split(p_dataset$Salary,SplitRatio = 0.9)
training_set = subset(p_dataset,to_split == TRUE)
test_set = subset(p_dataset,to_split == FALSE)
# training(fitting) the data_set simple linear
simp_regressor = lm(formula ='Salary ~ Level' ,
data = training_set)
# adding new coloum to dataset for polynomial
p_dataset$Level2 = p_dataset$Level^2 # take care of the input and output of dataset
training_set$Level2 = training_set$Level^2
training_set$Level3 = training_set$Level^3
training_set$Level4 = training_set$Level^4
training_set$Level5 = training_set$Level^5
# training(fitting) the data_set poly linear
poly_regressor = lm(formula ='Salary ~ Level + Level2 + Level3 + Level4 ' ,
data = training_set)
# visualizing simple linear
# Training set with test set
library(ggplot2)
p1 <- ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(simp_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = training_set$Level, y = predict(simp_regressor, newdata = training_set)),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
# adding new coloum to dataset (test set) to plot for polynomial
test_set$Level2 = test_set$Level^2
test_set$Level3 = test_set$Level^3
test_set$Level4 = test_set$Level^4
test_set$Level5 = test_set$Level^5
#install.packages("gridExtra") for displaying two plot
# visualizing poly linear
# Training set with test set
library(ggplot2)
y_pred_t = predict(poly_regressor, newdata = training_set)
x_grid_val = seq(min(training_set$Level), max(training_set$Level), 0.1)
y_grid_val = seq(min(y_pred_t), max(y_pred_t), 0.1)
p2 <-ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(poly_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = training_set$Level, y = data.frame(Level = y_grid_val)),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
#combining two graph p1 and p2
library(gridExtra)
grid.arrange(p1,p2,ncol=2)
# Summary of the simple regression and polynomial regression
print(summary(simp_regressor))
print(summary(poly_regressor))
p_dataset = read.csv("Position_Salaries.csv")
# spliting the data_set
library(caTools)
set.seed(123)
to_split = sample.split(p_dataset$Salary,SplitRatio = 0.9)
training_set = subset(p_dataset,to_split == TRUE)
test_set = subset(p_dataset,to_split == FALSE)
# training(fitting) the data_set simple linear
simp_regressor = lm(formula ='Salary ~ Level' ,
data = training_set)
# adding new coloum to dataset for polynomial
p_dataset$Level2 = p_dataset$Level^2 # take care of the input and output of dataset
training_set$Level2 = training_set$Level^2
training_set$Level3 = training_set$Level^3
training_set$Level4 = training_set$Level^4
training_set$Level5 = training_set$Level^5
# training(fitting) the data_set poly linear
poly_regressor = lm(formula ='Salary ~ Level + Level2 + Level3 + Level4 ' ,
data = training_set)
# visualizing simple linear
# Training set with test set
library(ggplot2)
p1 <- ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(simp_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = training_set$Level, y = predict(simp_regressor, newdata = training_set)),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
# adding new coloum to dataset (test set) to plot for polynomial
test_set$Level2 = test_set$Level^2
test_set$Level3 = test_set$Level^3
test_set$Level4 = test_set$Level^4
test_set$Level5 = test_set$Level^5
#install.packages("gridExtra") for displaying two plot
# visualizing poly linear
# Training set with test set
library(ggplot2)
y_pred_t = predict(poly_regressor, newdata = training_set)
x_grid_val = seq(min(training_set$Level), max(training_set$Level), 0.1)
y_grid_val = seq(min(y_pred_t), max(y_pred_t), 0.1)
p2 <- ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(poly_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = training_set$Level, y = data.frame(Level = y_grid_val)),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
#combining two graph p1 and p2
library(gridExtra)
grid.arrange(p1,p2,ncol=2)
# Summary of the simple regression and polynomial regression
print(summary(simp_regressor))
print(summary(poly_regressor))
grid.arrange(p1,p2,ncol=2)
p_dataset = read.csv("Position_Salaries.csv")
# spliting the data_set
library(caTools)
set.seed(123)
to_split = sample.split(p_dataset$Salary,SplitRatio = 0.9)
training_set = subset(p_dataset,to_split == TRUE)
test_set = subset(p_dataset,to_split == FALSE)
# training(fitting) the data_set simple linear
simp_regressor = lm(formula ='Salary ~ Level' ,
data = training_set)
# adding new coloum to dataset for polynomial
p_dataset$Level2 = p_dataset$Level^2 # take care of the input and output of dataset
training_set$Level2 = training_set$Level^2
training_set$Level3 = training_set$Level^3
training_set$Level4 = training_set$Level^4
training_set$Level5 = training_set$Level^5
# training(fitting) the data_set poly linear
poly_regressor = lm(formula ='Salary ~ Level + Level2 + Level3 + Level4 ' ,
data = training_set)
# visualizing simple linear
# Training set with test set
library(ggplot2)
p1 <- ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(simp_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = training_set$Level, y = predict(simp_regressor, newdata = training_set)),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
# adding new coloum to dataset (test set) to plot for polynomial
test_set$Level2 = test_set$Level^2
test_set$Level3 = test_set$Level^3
test_set$Level4 = test_set$Level^4
test_set$Level5 = test_set$Level^5
#install.packages("gridExtra") for displaying two plot
# visualizing poly linear
# Training set with test set
library(ggplot2)
y_pred_t = predict(poly_regressor, newdata = training_set)
x_grid_val = seq(min(training_set$Level), max(training_set$Level), 0.1)
y_grid_val = seq(min(y_pred_t), max(y_pred_t), 0.1)
p2 <- ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(poly_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = training_set$Level, y = y_grid_val),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
#combining two graph p1 and p2
library(gridExtra)
grid.arrange(p1,p2,ncol=2)
# Summary of the simple regression and polynomial regression
print(summary(simp_regressor))
print(summary(poly_regressor))
library(gridExtra)
grid.arrange(p1,p2,ncol=2)
p_dataset = read.csv("Position_Salaries.csv")
# spliting the data_set
library(caTools)
set.seed(123)
to_split = sample.split(p_dataset$Salary,SplitRatio = 0.9)
training_set = subset(p_dataset,to_split == TRUE)
test_set = subset(p_dataset,to_split == FALSE)
# training(fitting) the data_set simple linear
simp_regressor = lm(formula ='Salary ~ Level' ,
data = training_set)
# adding new coloum to dataset for polynomial
p_dataset$Level2 = p_dataset$Level^2 # take care of the input and output of dataset
training_set$Level2 = training_set$Level^2
training_set$Level3 = training_set$Level^3
training_set$Level4 = training_set$Level^4
training_set$Level5 = training_set$Level^5
# training(fitting) the data_set poly linear
poly_regressor = lm(formula ='Salary ~ Level + Level2 + Level3 + Level4 ' ,
data = training_set)
# visualizing simple linear
# Training set with test set
library(ggplot2)
p1 <- ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(simp_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = training_set$Level, y = predict(simp_regressor, newdata = training_set)),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
# adding new coloum to dataset (test set) to plot for polynomial
test_set$Level2 = test_set$Level^2
test_set$Level3 = test_set$Level^3
test_set$Level4 = test_set$Level^4
test_set$Level5 = test_set$Level^5
#install.packages("gridExtra") for displaying two plot
# visualizing poly linear
# Training set with test set
library(ggplot2)
y_pred_t = predict(poly_regressor, newdata = training_set)
x_grid_val = seq(min(training_set$Level), max(training_set$Level), 0.1)
y_grid_val = seq(min(y_pred_t), max(y_pred_t), 0.1)
p2 <- ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(poly_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = x_grid_val, y = y_grid_val),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
#combining two graph p1 and p2
library(gridExtra)
grid.arrange(p1,p2,ncol=2)
# Summary of the simple regression and polynomial regression
print(summary(simp_regressor))
print(summary(poly_regressor))
library(gridExtra)
grid.arrange(p1,p2,ncol=2)
geom_line(aes( x = x_grid_val, y = y_grid_val),
colour = 'blue')
geom_line(aes( x = x_grid_val, y = y_grid_val),
colour = 'blue')+
geom_line(aes( x = x_grid_val, y = y_grid_val),
colour = 'blue')+
library(ggplot2)
y_pred_t = predict(poly_regressor, newdata = training_set)
x_grid_val = seq(min(training_set$Level), max(training_set$Level), 0.1)
y_grid_val = seq(min(y_pred_t), max(y_pred_t), 0.1)
ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(poly_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = x_grid_val, y = y_grid_val),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
library(ggplot2)
y_pred_t = predict(poly_regressor, newdata = training_set)
x_grid_val = seq(min(training_set$Level), max(training_set$Level), 0.1)
y_grid_val = seq(min(y_pred_t), max(y_pred_t), 0.1)
ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")
ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(poly_regressor, newdata = test_set)),
colour = "red")
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(poly_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = x_grid_val, y = y_grid_val),
colour = 'blue')
y_pred_t = predict(poly_regressor, newdata = data.frame(Level = x_grid_val ))
p_dataset = read.csv("Position_Salaries.csv")
# spliting the data_set
library(caTools)
set.seed(123)
to_split = sample.split(p_dataset$Salary,SplitRatio = 0.9)
training_set = subset(p_dataset,to_split == TRUE)
test_set = subset(p_dataset,to_split == FALSE)
# training(fitting) the data_set simple linear
simp_regressor = lm(formula ='Salary ~ Level' ,
data = training_set)
# adding new coloum to dataset for polynomial
p_dataset$Level2 = p_dataset$Level^2 # take care of the input and output of dataset
training_set$Level2 = training_set$Level^2
training_set$Level3 = training_set$Level^3
training_set$Level4 = training_set$Level^4
training_set$Level5 = training_set$Level^5
# training(fitting) the data_set poly linear
poly_regressor = lm(formula ='Salary ~ Level + Level2 + Level3 + Level4 ' ,
data = training_set)
# visualizing simple linear
# Training set with test set
library(ggplot2)
p1 <- ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(simp_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = training_set$Level, y = predict(simp_regressor, newdata = training_set)),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
# adding new coloum to dataset (test set) to plot for polynomial
test_set$Level2 = test_set$Level^2
test_set$Level3 = test_set$Level^3
test_set$Level4 = test_set$Level^4
test_set$Level5 = test_set$Level^5
#install.packages("gridExtra") for displaying two plot
# visualizing poly linear
# Training set with test set
library(ggplot2)
p2 <-ggplot() +
geom_point(aes( x = training_set$Level, y = training_set$Salary),
colour = "Green")+
geom_point(aes(x = test_set$Level, y = predict(poly_regressor, newdata = test_set)),
colour = "red")+
geom_line(aes( x = training_set$Level, y = predict(poly_regressor, newdata = training_set)),
colour = 'blue')+
ggtitle("Salary Prediction ")+
xlab("position")+
ylab("Salary")
#combining two graph p1 and p2
library(gridExtra)
grid.arrange(p1,p2,ncol=2)
# Summary of the simple regression and polynomial regression
print(summary(simp_regressor))
print(summary(poly_regressor))
